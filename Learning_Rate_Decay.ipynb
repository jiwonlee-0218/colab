{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Learning_Rate_Decay.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiwonlee-0218/colab/blob/main/Learning_Rate_Decay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AcFwwBq6qaO"
      },
      "source": [
        "# Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iHTZSe06qaY"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qkgkIn-6qaZ"
      },
      "source": [
        "# 0. 기존 작업"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XOF34Ql6qaa"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    \n",
        "seed_everything()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N71iGdB6qab"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(x, y), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "x = x.astype('float32') \n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y = to_categorical(y, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33SM0uLg6qac"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWNnDoT46qad"
      },
      "source": [
        "lr = 0.01\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7azauZA6qad"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5EiznNo6qae",
        "outputId": "325b12d3-6a1e-4e4d-ace3-65449bdfc785"
      },
      "source": [
        "def create_model(learning_rate=lr, momentum = momentum):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28)))\n",
        "    model.add(Dense(units=32, activation='relu'))\n",
        "    model.add(Dense(64, 'relu'))\n",
        "    model.add(Dense(128, 'relu'))\n",
        "    model.add(Dense(units=10, activation='softmax'))\n",
        "    \n",
        "    sgd = SGD(learning_rate=learning_rate, momentum=momentum, nesterov=False)\n",
        "    model.compile(optimizer=sgd, \n",
        "                  loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_4 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 36,842\n",
            "Trainable params: 36,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YE7_PPY6qaf"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw70ajfb6qag"
      },
      "source": [
        "# 1. schedule 함수 만들기\n",
        "\n",
        "epoch의 값에 따라 learning_rate가 변하는 함수를 만들면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZMkkTNe6qah"
      },
      "source": [
        "def my_schedule(epoch, learning_rate=lr):\n",
        "    if epoch < 5:\n",
        "        return lr\n",
        "    else:\n",
        "        return float(lr * tf.math.exp(0.1 * (5- epoch)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy0ESvYm6qah"
      },
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up01-QPD6qah"
      },
      "source": [
        "lr_schedule_custom = LearningRateScheduler(my_schedule, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zJdSBna6qai",
        "outputId": "2309a236-8bdf-49b8-bd42-928ad629f84f"
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "model.fit(x, y,  epochs = 20, validation_split = 1/6, callbacks = [lr_schedule_custom], batch_size=512, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.01.\n",
            "98/98 [==============================] - 2s 12ms/step - loss: 1.8717 - accuracy: 0.2971 - val_loss: 0.7189 - val_accuracy: 0.7420\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.01.\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6734 - accuracy: 0.7600 - val_loss: 0.5721 - val_accuracy: 0.7964\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.01.\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.5441 - accuracy: 0.8099 - val_loss: 0.5153 - val_accuracy: 0.8174\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.01.\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4881 - accuracy: 0.8296 - val_loss: 0.4873 - val_accuracy: 0.8266\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.01.\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4589 - accuracy: 0.8405 - val_loss: 0.4734 - val_accuracy: 0.8327\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4391 - accuracy: 0.8478 - val_loss: 0.4624 - val_accuracy: 0.8372\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.009048374369740486.\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4233 - accuracy: 0.8528 - val_loss: 0.4511 - val_accuracy: 0.8393\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.008187307976186275.\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4106 - accuracy: 0.8571 - val_loss: 0.4341 - val_accuracy: 0.8467\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.007408181671053171.\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.3998 - accuracy: 0.8599 - val_loss: 0.4331 - val_accuracy: 0.8433\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.006703200284391642.\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3930 - accuracy: 0.8613 - val_loss: 0.4440 - val_accuracy: 0.8393\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.006065306719392538.\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3880 - accuracy: 0.8622 - val_loss: 0.4424 - val_accuracy: 0.8403\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.005488115828484297.\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.3847 - accuracy: 0.8640 - val_loss: 0.4275 - val_accuracy: 0.8464\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0049658529460430145.\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3807 - accuracy: 0.8651 - val_loss: 0.4131 - val_accuracy: 0.8525\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0044932896271348.\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3765 - accuracy: 0.8675 - val_loss: 0.4012 - val_accuracy: 0.8594\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 0.004065696615725756.\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3720 - accuracy: 0.8693 - val_loss: 0.3946 - val_accuracy: 0.8641\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0036787944845855236.\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3665 - accuracy: 0.8717 - val_loss: 0.3920 - val_accuracy: 0.8651\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0033287107944488525.\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3616 - accuracy: 0.8739 - val_loss: 0.3899 - val_accuracy: 0.8637\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 0.003011941909790039.\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.3583 - accuracy: 0.8740 - val_loss: 0.3877 - val_accuracy: 0.8651\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0027253180742263794.\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.3558 - accuracy: 0.8751 - val_loss: 0.3858 - val_accuracy: 0.8662\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0024659696500748396.\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3539 - accuracy: 0.8760 - val_loss: 0.3847 - val_accuracy: 0.8666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x170e32935e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wrk5MYK6qaj"
      },
      "source": [
        "# 2. tensorflow의 scheduler 사용\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu85XBKR6qaj"
      },
      "source": [
        "**def** decayed_learning_rate(step):\n",
        "\n",
        "  > return initial_learning_rate * decay_rate ^ (step / decay_steps)\n",
        "  \n",
        "  \n",
        "`decay_steps` 마다 `decay_rate`의 비율로 감소"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX-MddJs6qak"
      },
      "source": [
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkXVQwDh6qak"
      },
      "source": [
        "lr_scheduler_exp = ExponentialDecay(lr, decay_steps=10000, decay_rate=0.96, staircase=False, name=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aFcIaTf6qak"
      },
      "source": [
        "def exp_model(learning_rate=lr, momentum = momentum):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28)))\n",
        "    model.add(Dense(units=32, activation='relu'))\n",
        "    model.add(Dense(64, 'relu'))\n",
        "    model.add(Dense(128, 'relu'))\n",
        "    model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbauyWDL6qak",
        "outputId": "4ddbca4e-c1ae-4536-f0e9-51d15427cb7d"
      },
      "source": [
        "model = exp_model()\n",
        "sgd = SGD(learning_rate=lr_scheduler_exp, momentum=momentum, nesterov=False)\n",
        "model.compile(optimizer=sgd, \n",
        "                  loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x, y,  epochs = 20, validation_split = 1/6, batch_size=512)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "98/98 [==============================] - 2s 9ms/step - loss: 1.8679 - accuracy: 0.3248 - val_loss: 0.7503 - val_accuracy: 0.7056\n",
            "Epoch 2/20\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6764 - accuracy: 0.7534 - val_loss: 0.6110 - val_accuracy: 0.7713\n",
            "Epoch 3/20\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5511 - accuracy: 0.8059 - val_loss: 0.5147 - val_accuracy: 0.8195\n",
            "Epoch 4/20\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.4957 - accuracy: 0.8273 - val_loss: 0.4786 - val_accuracy: 0.8290\n",
            "Epoch 5/20\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4655 - accuracy: 0.8365 - val_loss: 0.4751 - val_accuracy: 0.8266\n",
            "Epoch 6/20\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.4463 - accuracy: 0.8406 - val_loss: 0.4409 - val_accuracy: 0.8402\n",
            "Epoch 7/20\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4195 - accuracy: 0.8543 - val_loss: 0.4818 - val_accuracy: 0.8271\n",
            "Epoch 8/20\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4251 - accuracy: 0.8512 - val_loss: 0.4495 - val_accuracy: 0.8382\n",
            "Epoch 9/20\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4128 - accuracy: 0.8544 - val_loss: 0.4285 - val_accuracy: 0.8478\n",
            "Epoch 10/20\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3916 - accuracy: 0.8639 - val_loss: 0.4193 - val_accuracy: 0.8512\n",
            "Epoch 11/20\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3906 - accuracy: 0.8643 - val_loss: 0.4023 - val_accuracy: 0.8586\n",
            "Epoch 12/20\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3724 - accuracy: 0.8685 - val_loss: 0.4050 - val_accuracy: 0.8567\n",
            "Epoch 13/20\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3723 - accuracy: 0.8682 - val_loss: 0.3921 - val_accuracy: 0.8644\n",
            "Epoch 14/20\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3733 - accuracy: 0.8695 - val_loss: 0.3960 - val_accuracy: 0.8640\n",
            "Epoch 15/20\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3560 - accuracy: 0.8743 - val_loss: 0.4116 - val_accuracy: 0.8560\n",
            "Epoch 16/20\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3525 - accuracy: 0.8752 - val_loss: 0.3821 - val_accuracy: 0.8672\n",
            "Epoch 17/20\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3502 - accuracy: 0.8757 - val_loss: 0.3807 - val_accuracy: 0.8675\n",
            "Epoch 18/20\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3416 - accuracy: 0.8787 - val_loss: 0.3731 - val_accuracy: 0.8715\n",
            "Epoch 19/20\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3423 - accuracy: 0.8804 - val_loss: 0.3719 - val_accuracy: 0.8697\n",
            "Epoch 20/20\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3327 - accuracy: 0.8818 - val_loss: 0.3733 - val_accuracy: 0.8694\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x170e21976a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbAHGyMM6qak",
        "outputId": "64cdac3f-599d-4ecf-f0e7-643e942b6ad8"
      },
      "source": [
        "model.optimizer.lr(100000) # 0.96^10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0066483244>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yu1Algw6qal"
      },
      "source": [
        "# 3. ReduceLRonPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCwIeqTywmY1"
      },
      "source": [
        "- monitor에 'val_loss'를 입력하면 val_loss가 더이상 감소되지 않을 경우 ReduceLROnPlateau을 적용합니다.\n",
        "\n",
        "- factor은 Learning rate를 얼마나 감소시킬 지 정하는 인자값입니다.\n",
        "새로운 learning rate는 기존 learning rate * factor입니다.\n",
        "\n",
        "- patience는 patience는 3이고, 30에폭에 정확도가 99%였을 때,\n",
        "만약 31번째에 정확도 98%, 32번째에 98.5%, 33번째에 98%라면 모델의 개선이 (patience=3)동안 개선이 없었기에,  ReduceLROnPlateau 콜백함수를 실행합니다.\n",
        "\n",
        "- verbose는 화면에 적용되었다고 나타냅니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTqUuUng6qal"
      },
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPelSws-6qal"
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_gXfPMR6qal",
        "outputId": "a824dc66-d15c-4e26-f934-7657945fc551"
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "model.fit(x, y,  epochs = 30, validation_split = 1/6, callbacks = [reduce_lr], batch_size=512, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.7674 - accuracy: 0.3914 - val_loss: 0.7005 - val_accuracy: 0.7457\n",
            "Epoch 2/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.6573 - accuracy: 0.7665 - val_loss: 0.5628 - val_accuracy: 0.8001\n",
            "Epoch 3/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.5363 - accuracy: 0.8126 - val_loss: 0.5209 - val_accuracy: 0.8119\n",
            "Epoch 4/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4878 - accuracy: 0.8296 - val_loss: 0.4969 - val_accuracy: 0.8195\n",
            "Epoch 5/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4600 - accuracy: 0.8400 - val_loss: 0.4751 - val_accuracy: 0.8280\n",
            "Epoch 6/30\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4397 - accuracy: 0.8466 - val_loss: 0.4625 - val_accuracy: 0.8350\n",
            "Epoch 7/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4239 - accuracy: 0.8515 - val_loss: 0.4564 - val_accuracy: 0.8367\n",
            "Epoch 8/30\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8548 - val_loss: 0.4510 - val_accuracy: 0.8390\n",
            "Epoch 9/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4006 - accuracy: 0.8582 - val_loss: 0.4427 - val_accuracy: 0.8451\n",
            "Epoch 10/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3911 - accuracy: 0.8613 - val_loss: 0.4336 - val_accuracy: 0.8470\n",
            "Epoch 11/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3825 - accuracy: 0.8639 - val_loss: 0.4258 - val_accuracy: 0.8490\n",
            "Epoch 12/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3751 - accuracy: 0.8655 - val_loss: 0.4195 - val_accuracy: 0.8509\n",
            "Epoch 13/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3682 - accuracy: 0.8680 - val_loss: 0.4177 - val_accuracy: 0.8511\n",
            "Epoch 14/30\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3628 - accuracy: 0.8697 - val_loss: 0.4133 - val_accuracy: 0.8529\n",
            "Epoch 15/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3571 - accuracy: 0.8718 - val_loss: 0.4098 - val_accuracy: 0.8523\n",
            "Epoch 16/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3517 - accuracy: 0.8736 - val_loss: 0.4074 - val_accuracy: 0.8534\n",
            "Epoch 17/30\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3467 - accuracy: 0.8756 - val_loss: 0.4048 - val_accuracy: 0.8540\n",
            "Epoch 18/30\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.3425 - accuracy: 0.8767 - val_loss: 0.4007 - val_accuracy: 0.8557\n",
            "Epoch 19/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3382 - accuracy: 0.8785 - val_loss: 0.3937 - val_accuracy: 0.8590\n",
            "Epoch 20/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3331 - accuracy: 0.8796 - val_loss: 0.3932 - val_accuracy: 0.8591\n",
            "Epoch 21/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3293 - accuracy: 0.8812 - val_loss: 0.3891 - val_accuracy: 0.8617\n",
            "Epoch 22/30\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3251 - accuracy: 0.8826 - val_loss: 0.3878 - val_accuracy: 0.8621\n",
            "Epoch 23/30\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.3215 - accuracy: 0.8835 - val_loss: 0.3858 - val_accuracy: 0.8629\n",
            "Epoch 24/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3177 - accuracy: 0.8852 - val_loss: 0.3846 - val_accuracy: 0.8639\n",
            "Epoch 25/30\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3141 - accuracy: 0.8868 - val_loss: 0.3832 - val_accuracy: 0.8638\n",
            "Epoch 26/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3107 - accuracy: 0.8877 - val_loss: 0.3826 - val_accuracy: 0.8634\n",
            "Epoch 27/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3075 - accuracy: 0.8890 - val_loss: 0.3822 - val_accuracy: 0.8638\n",
            "Epoch 28/30\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3044 - accuracy: 0.8896 - val_loss: 0.3839 - val_accuracy: 0.8633\n",
            "Epoch 29/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3016 - accuracy: 0.8900 - val_loss: 0.3838 - val_accuracy: 0.8637\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "Epoch 30/30\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3030 - accuracy: 0.8899 - val_loss: 0.3494 - val_accuracy: 0.8761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x170e34eb8e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    }
  ]
}